from .event_loop_policy import *
from fastapi import FastAPI, HTTPException
from .scraper import scrape_site, PlaywrightScraper
from .llm import *
from bs4 import BeautifulSoup
import re
from .llm import _sanitize_and_validate_html


def keep_from_html(raw: str) -> str:
    """
    Extract the HTML content while preserving the entire document structure.
    Returns the full HTML document if valid, otherwise returns the original string.
    """
    try:
        soup = BeautifulSoup(raw, 'html.parser')
        if not soup.find('html'):
            return raw
        return str(soup)
    except Exception:
        return raw

app = FastAPI()

from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
  CORSMiddleware,
  allow_origins=["http://localhost:3000"],  # your dev origin
  allow_credentials=True,
  allow_methods=["*"],
  allow_headers=["*"],
)


@app.get("/")
def read_root():
    return {"message": "Hello World"}


# This is only to test that the scraper is working for me as a developer and is NOT used by the frontend
@app.post("/api/clone")
async def clone_website(payload: dict):
    url = payload.get("url")
    if not url:
        raise HTTPException(status_code=400, detail="URL is required")
    result = await scrape_site(url)
    if result["error"] is not None:
        raise HTTPException(status_code=500, detail=result["error"])
    return {
        "html": result["html"],
        "css": result["css"],
        "images": result["images"],
        "metadata": result["metadata"],
    }


# This is the main endpoint for cloning a website and it is used by the frontend
@app.post("/api/clone/stream")
async def clone_stream(payload: dict):
    url = payload["url"]
    result = await scrape_site(url)

    if result["error"] is not None:
        raise HTTPException(status_code=500, detail=result["error"])

    html = result["html"]
    css = result["css"]
    images = result["images"]
    metadata = result["metadata"]

    model_config = choose_model()
    provider, model_name = model_config["provider"], model_config["model"]

    try:
        clone_raw_html = await generate_clone_html(scraped_html=html, scraped_css_list=css, metadata=metadata)
        
        # Debug: Log the raw LLM output
        print(f"Raw LLM output length: {len(clone_raw_html)}")
        print(f"Raw LLM output starts with: {clone_raw_html[:100]}")
        
        clone_html = strip_markdown_code_blocks(clone_raw_html)
        
        # Debug: Log after markdown stripping
        print(f"After markdown stripping length: {len(clone_html)}")
        print(f"After markdown stripping starts with: {clone_html[:100]}")
        
        # Content verification and regeneration attempt
        clone_html = verify_and_fix_content(clone_html, html, css, metadata)
        
        clone_html = _sanitize_and_validate_html(clone_html)
        
        # Check if the body is empty and create fallback if needed
        soup = BeautifulSoup(clone_html, 'html.parser')
        body = soup.find('body')
        if body and len(body.get_text(strip=True)) < 50:
            print("‚ö†Ô∏è LLM returned empty body, creating fallback...")
            # Create a fallback using the original scraped content
            clone_html = create_fallback_html(html, css, metadata)
        
        html_only = keep_from_html(clone_html)
        
        # Ensure we have a valid HTML document
        if not html_only.strip().startswith("<!DOCTYPE html>"):
            html_only = "<!DOCTYPE html>\n" + html_only
        
        # Final validation - ensure the HTML actually has meaningful content
        final_soup = BeautifulSoup(html_only, 'html.parser')
        final_body = final_soup.find('body')
        if final_body:
            final_text = final_body.get_text(strip=True)
            final_elements = final_body.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'div', 'span', 'img', 'a', 'button', 'nav', 'main', 'section', 'article'])
            final_visible = [elem for elem in final_elements if elem.get_text(strip=True) or elem.name in ['img', 'button']]
            
            print(f"Final body validation - text length: {len(final_text)}")
            print(f"Final body validation - visible elements: {len(final_visible)}")
            print(f"Final body preview: {final_text[:300]}")
            
            # If we still don't have enough content, create emergency content
            if len(final_text) < 100 and len(final_visible) < 10:
                print("üö® FINAL EMERGENCY FALLBACK: Creating substantial emergency content")
                html_only = create_emergency_content(html, css, metadata)
        
        return {
            "clone_html": html_only,
            "images": images,
            "metadata": metadata,
            "original_css": css  # Include original CSS for reference
        }
    except Exception as e:
        print(f"LLM generation error: {e}")
        raise HTTPException(status_code=500, detail=f"LLM generation failed: {e}")
    

@app.on_event("shutdown")
async def shutdown_event():
    await PlaywrightScraper.close()

def strip_markdown_code_blocks(text: str) -> str:
    """
    Removes leading/trailing markdown code block (``` or ```html) from LLM output.
    """
    if not text or not isinstance(text, str):
        return text
    
    # Remove leading/trailing whitespace
    text = text.strip()
    
    # Try multiple patterns to catch different markdown formats
    patterns = [
        r"^```html\s*([\s\S]*?)\s*```$",  # ```html ... ```
        r"^```\s*([\s\S]*?)\s*```$",     # ``` ... ```
        r"^`{3,}\w*\s*([\s\S]*?)\s*`{3,}$",  # Multiple backticks
    ]
    
    for pattern in patterns:
        match = re.match(pattern, text, re.IGNORECASE | re.DOTALL)
        if match:
            extracted = match.group(1).strip()
            print(f"Stripped markdown code block, extracted {len(extracted)} characters")
            return extracted
    
    # If no markdown found, return original
    print("No markdown code block found")
    return text

def create_fallback_html(original_html: str, css_list: list, metadata: dict) -> str:
    """
    Create a fallback HTML page that preserves original styling and branding.
    Extracts colors, fonts, and styling from the original website.
    """
    soup = BeautifulSoup(original_html, 'html.parser')
    
    # Extract title and basic metadata
    title = metadata.get('title', 'Cloned Website') if metadata else 'Cloned Website'
    site_url = metadata.get('url', 'Unknown Site') if metadata else 'Unknown Site'
    
    # Try to extract meaningful content from the original using generic patterns
    content_elements = []
    
    # 1. Look for main content areas (common across all sites)
    main_areas = soup.find_all(['main', 'article', '[role="main"]', '#main', '.main', '.content', '#content'])
    for area in main_areas[:3]:  # Limit to first 3 main areas
        area_text = area.get_text(strip=True)
        if len(area_text) > 50:
            content_elements.append(f'<div class="main-content">{area_text[:500]}...</div>')
    
    # 2. Look for navigation elements (universal)
    nav_elements = soup.find_all(['nav', 'header', '[role="navigation"]', '.nav', '.navbar', '.menu'])
    for nav in nav_elements[:2]:  # Limit to first 2 nav elements
        nav_text = nav.get_text(strip=True)
        if len(nav_text) > 10 and len(nav_text) < 200:  # Reasonable nav size
            content_elements.append(f'<div class="nav-content"><strong>Navigation:</strong> {nav_text}</div>')
    
    # 3. Look for headings (universal content indicators)
    headings = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
    for heading in headings[:8]:  # Limit to first 8 headings
        heading_text = heading.get_text(strip=True)
        if len(heading_text) > 3 and len(heading_text) < 100:
            level = heading.name
            content_elements.append(f'<{level} class="extracted-heading">{heading_text}</{level}>')
    
    # 4. Look for substantial paragraphs and text blocks
    text_elements = soup.find_all(['p', 'div', 'span', 'section'])
    added_text = set()
    for elem in text_elements[:15]:  # Limit to first 15 text elements
        text_content = elem.get_text(strip=True)
        if (len(text_content) > 30 and 
            len(text_content) < 300 and 
            text_content not in added_text and
            not text_content.lower().startswith(('cookie', 'privacy', 'terms'))):  # Skip legal text
            added_text.add(text_content)
            content_elements.append(f'<p class="extracted-text">{text_content}</p>')
    
    # 5. Look for lists (common content structure)
    lists = soup.find_all(['ul', 'ol'])
    for list_elem in lists[:3]:  # Limit to first 3 lists
        list_text = list_elem.get_text(strip=True)
        if len(list_text) > 20 and len(list_text) < 200:
            content_elements.append(f'<div class="list-content">{str(list_elem)}</div>')
    
    # 6. Look for images with alt text or captions
    images = soup.find_all('img')
    image_count = 0
    for img in images:
        if img.get('src') and image_count < 5:  # Limit to first 5 images
            alt_text = img.get('alt', 'Image')
            src = img.get('src')
            content_elements.append(f'<div class="image-container"><img src="{src}" alt="{alt_text}" style="max-width: 100%; height: auto;"><p><em>{alt_text}</em></p></div>')
            image_count += 1
    
    # 7. If we still don't have much content, extract visible text in chunks
    if len(content_elements) < 5:
        all_text = soup.get_text(strip=True)
        words = all_text.split()
        if len(words) > 100:
            # Take meaningful chunks of text
            for i in range(0, min(len(words), 400), 80):
                chunk = ' '.join(words[i:i+80])
                if len(chunk.strip()) > 50:
                    content_elements.append(f'<p class="extracted-chunk">{chunk}</p>')
                if len(content_elements) >= 8:  # Don't overwhelm with too much content
                    break
    
    # Extract original styling from CSS
    original_colors = extract_colors_from_css(css_list)
    original_fonts = extract_fonts_from_css(css_list)
    
    # Use extracted colors or fallback to colors found in HTML
    primary_color = original_colors.get('primary', '#007bff')
    background_color = original_colors.get('background', '#ffffff')
    text_color = original_colors.get('text', '#333333')
    accent_color = original_colors.get('accent', primary_color)
    
    # Use extracted fonts
    primary_font = original_fonts.get('primary', '-apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Arial, sans-serif')
    
    # Include original CSS with modifications for static display
    combined_css = ""
    if css_list:
        combined_css = "\n".join(css_list)
        # Remove animations and transitions for static version
        combined_css = remove_animations_from_css(combined_css)
    
    # CSS that uses original styling but ensures content is visible
    enhanced_css = f"""
        /* Original CSS preserved */
        {combined_css}
        
        /* Enhancements for extracted content display */
        body {{
            font-family: {primary_font};
            background-color: {background_color};
            color: {text_color};
            margin: 0;
            padding: 20px;
            line-height: 1.6;
        }}
        .fallback-container {{
            max-width: 1200px;
            margin: 0 auto;
            background: {background_color};
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            overflow: hidden;
        }}
        .fallback-header {{
            background: {primary_color};
            color: white;
            padding: 20px;
            text-align: center;
        }}
        .fallback-content {{
            padding: 20px;
        }}
        .main-content, .extracted-text, .nav-content, .extracted-chunk, .list-content {{
            margin-bottom: 15px;
            padding: 15px;
            border-left: 3px solid {accent_color};
            background: rgba(0,0,0,0.02);
            border-radius: 4px;
        }}
        .extracted-heading {{
            color: {primary_color};
            margin: 20px 0 10px 0;
        }}
        .image-container {{
            margin: 15px 0;
            text-align: center;
            background: rgba(0,0,0,0.02);
            padding: 15px;
            border-radius: 4px;
        }}
        .fallback-notice {{
            background: rgba(33, 150, 243, 0.1);
            border: 1px solid {accent_color};
            border-radius: 5px;
            padding: 15px;
            margin-bottom: 20px;
        }}
        .stats {{
            display: flex;
            justify-content: space-around;
            background: rgba(0,0,0,0.02);
            padding: 15px;
            margin: 20px 0;
            border-radius: 4px;
            flex-wrap: wrap;
        }}
        .stat {{
            text-align: center;
            margin: 5px;
        }}
        .nav-content {{
            background: rgba(255, 193, 7, 0.1);
            border-left-color: {accent_color};
        }}
    """
    
    # Create fallback HTML that preserves original branding
    fallback_html = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>{enhanced_css}</style>
</head>
<body>
    <div class="fallback-container">
        <div class="fallback-header">
            <h1>üìÑ {title}</h1>
            <p>Static Clone - Original Styling Preserved</p>
        </div>
        
        <div class="fallback-content">
            <div class="fallback-notice">
                <h3>üîÑ Content Extracted with Original Styling</h3>
                <p>This fallback preserves the original website's colors, fonts, and styling while displaying the extracted content:</p>
            </div>
            
            <div class="stats">
                <div class="stat">
                    <strong>{len(content_elements)}</strong><br>
                    <small>Content Blocks</small>
                </div>
                <div class="stat">
                    <strong>{len(images)}</strong><br>
                    <small>Images Found</small>
                </div>
                <div class="stat">
                    <strong>{len(css_list)}</strong><br>
                    <small>CSS Files</small>
                </div>
                <div class="stat">
                    <strong>{len(soup.get_text().split())}</strong><br>
                    <small>Total Words</small>
                </div>
            </div>
            
            <div class="extracted-content">
                {"".join(content_elements) if content_elements else f"<div class='main-content'><h2>‚ö†Ô∏è Limited Content Extracted</h2><p>Could not extract substantial content from {title}. This appears to be a heavily JavaScript-dependent website that requires dynamic rendering to display content.</p><p>The original page likely loads content after initial page load, making it difficult to extract in a static format.</p></div>"}
            </div>
        </div>
    </div>
</body>
</html>"""
    
    return fallback_html

def extract_colors_from_css(css_list: list) -> dict:
    """Extract colors from CSS to preserve original color scheme with enhanced gradient support."""
    colors = {'primary': '#007bff', 'background': '#ffffff', 'text': '#333333', 'accent': '#007bff'}
    
    if not css_list:
        return colors
    
    combined_css = ' '.join(css_list)
    
    # Look for gradient patterns specifically
    gradient_patterns = [
        r'linear-gradient\([^)]+\)',
        r'radial-gradient\([^)]+\)',
        r'conic-gradient\([^)]+\)',
    ]
    
    gradients = []
    for pattern in gradient_patterns:
        found_gradients = re.findall(pattern, combined_css, re.IGNORECASE)
        gradients.extend(found_gradients)
    
    # If we find gradients, extract the first gradient as the primary background
    if gradients:
        colors['background'] = gradients[0]
        print(f"Found gradient background: {gradients[0]}")
    
    # Look for common color patterns
    hex_colors = re.findall(r'#([0-9a-fA-F]{3,6})', combined_css)
    rgb_colors = re.findall(r'rgb\([^)]+\)', combined_css)
    rgba_colors = re.findall(r'rgba\([^)]+\)', combined_css)
    
    # Enhanced color context detection
    color_contexts = [
        (r'background(?:-color)?:\s*([^;}\n]+)', 'background'),
        (r'color:\s*([^;}\n]+)', 'text'),
        (r'border-color:\s*([^;}\n]+)', 'accent'),
        (r'--[\w-]*color[\w-]*:\s*([^;}\n]+)', 'primary'),  # CSS variables with "color" in name
    ]
    
    for pattern, color_type in color_contexts:
        matches = re.findall(pattern, combined_css, re.IGNORECASE)
        if matches:
            for match in matches:
                color_value = match.strip()
                if color_value and not color_value.startswith('var(') and not color_value == 'inherit':
                    colors[color_type] = color_value
                    break  # Use first valid match
    
    # Set primary color to the most vibrant/distinct color found
    if hex_colors:
        # Prefer longer hex codes (6 digits over 3)
        long_hex = [c for c in hex_colors if len(c) == 6]
        if long_hex:
            colors['primary'] = f"#{long_hex[0]}"
        else:
            colors['primary'] = f"#{hex_colors[0]}"
    
    return colors


def extract_fonts_from_css(css_list: list) -> dict:
    """Extract font families from CSS to preserve original typography."""
    fonts = {'primary': '-apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Arial, sans-serif'}
    
    if not css_list:
        return fonts
    
    combined_css = ' '.join(css_list)
    
    # Look for font-family declarations
    font_matches = re.findall(r'font-family:\s*([^;]+)', combined_css, re.IGNORECASE)
    if font_matches:
        # Use the first non-variable font family found
        for font in font_matches:
            font = font.strip()
            if font and not font.startswith('var('):
                fonts['primary'] = font
                break
    
    return fonts


def remove_animations_from_css(css: str) -> str:
    """Remove animations and transitions from CSS for static display while preserving gradients and visual effects."""
    # Remove animation properties but preserve transforms that affect layout
    css = re.sub(r'animation[^;]*;', '', css, flags=re.IGNORECASE)
    css = re.sub(r'transition[^;]*;', '', css, flags=re.IGNORECASE)
    
    # Only remove transforms that are clearly animation-related (translate, rotate, scale with transitions)
    # Keep static transforms that affect layout
    css = re.sub(r'transform:\s*(?:translate|rotate|scale)[^;]*;', '', css, flags=re.IGNORECASE)
    
    # Remove keyframes entirely
    css = re.sub(r'@keyframes[^{]*\{[^}]*\}', '', css, flags=re.IGNORECASE | re.DOTALL)
    
    # Preserve background gradients explicitly (ensure they don't get accidentally removed)
    # Add comments to mark preserved gradients
    if 'gradient(' in css.lower():
        css = '/* Background gradients preserved for visual fidelity */\n' + css
    
    return css

def verify_and_fix_content(clone_html: str, original_html: str, css_list: list, metadata: dict) -> str:
    """
    Verify that the cloned HTML has substantial content and fix if needed.
    """
    # Check body content BEFORE sanitization
    soup_check = BeautifulSoup(clone_html, 'html.parser')
    body_check = soup_check.find('body')
    
    if not body_check:
        print("‚ùå NO BODY TAG FOUND!")
        return create_fallback_html(original_html, css_list, metadata)
    
    body_text = body_check.get_text(strip=True)
    body_html_content = str(body_check)
    
    print(f"Body text length: {len(body_text)}")
    print(f"Body HTML length: {len(body_html_content)}")
    print(f"Body content preview: {body_text[:200]}")
    print(f"Body HTML preview: {body_html_content[:500]}")
    
    # Count meaningful elements in body
    meaningful_elements = body_check.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'div', 'span', 'img', 'a', 'button', 'nav', 'main', 'section', 'article'])
    visible_elements = [elem for elem in meaningful_elements if elem.get_text(strip=True) or elem.name in ['img', 'button']]
    
    print(f"Total elements in body: {len(meaningful_elements)}")
    print(f"Elements with visible content: {len(visible_elements)}")
    
    # More aggressive content checking
    has_sufficient_text = len(body_text) >= 100
    has_sufficient_elements = len(visible_elements) >= 10
    has_navigation = bool(body_check.find(['nav', 'header']))
    has_main_content = bool(body_check.find(['main', 'article', '[role="main"]']))
    
    print(f"Content checks:")
    print(f"  - Sufficient text ({len(body_text)} >= 100): {has_sufficient_text}")
    print(f"  - Sufficient elements ({len(visible_elements)} >= 10): {has_sufficient_elements}")
    print(f"  - Has navigation: {has_navigation}")
    print(f"  - Has main content: {has_main_content}")
    
    # If content is insufficient, use fallback
    if not (has_sufficient_text or (has_sufficient_elements and (has_navigation or has_main_content))):
        print("üö® FORCING FALLBACK: Body has insufficient content")
        print(f"Reason: Text {len(body_text)} < 100 AND (elements {len(visible_elements)} < 10 OR missing nav/main)")
        return create_fallback_html(original_html, css_list, metadata)
    
    print("‚úÖ Content verification passed")
    return clone_html

def create_emergency_content(original_html: str, css_list: list, metadata: dict) -> str:
    """
    Create emergency content when all other methods fail.
    This creates a more substantial page with recreated content.
    """
    soup = BeautifulSoup(original_html, 'html.parser')
    title = metadata.get('title', 'Website Clone') if metadata else 'Website Clone'
    
    # Extract original styling
    original_colors = extract_colors_from_css(css_list)
    original_fonts = extract_fonts_from_css(css_list)
    
    primary_color = original_colors.get('primary', '#007bff')
    background_color = original_colors.get('background', '#ffffff')
    text_color = original_colors.get('text', '#333333')
    primary_font = original_fonts.get('primary', '-apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Arial, sans-serif')
    
    # Extract substantial content
    all_text = soup.get_text(separator=' ', strip=True)
    words = all_text.split()
    
    # Create meaningful content sections
    content_sections = []
    
    # Add navigation-like content
    nav_elements = soup.find_all(['nav', 'header', '[role="navigation"]'])
    nav_text = ' '.join([elem.get_text(strip=True) for elem in nav_elements[:2]])
    if nav_text:
        content_sections.append(f'<nav style="background: {primary_color}; color: white; padding: 15px; margin-bottom: 20px; border-radius: 4px;"><h3 style="margin: 0; color: white;">Navigation</h3><p style="margin: 5px 0 0 0; color: rgba(255,255,255,0.9);">{nav_text[:200]}...</p></nav>')
    
    # Add main content sections
    headings = soup.find_all(['h1', 'h2', 'h3'])
    for i, heading in enumerate(headings[:5]):
        heading_text = heading.get_text(strip=True)
        if heading_text and len(heading_text) > 3:
            content_sections.append(f'<section style="margin: 20px 0; padding: 20px; border-left: 4px solid {primary_color}; background: rgba(0,0,0,0.02);"><h2 style="color: {primary_color}; margin-top: 0;">{heading_text}</h2><p>Content section extracted from the original website.</p></section>')
    
    # Add text content in chunks
    if len(words) > 50:
        for i in range(0, min(len(words), 300), 60):
            chunk = ' '.join(words[i:i+60])
            if chunk.strip():
                content_sections.append(f'<div style="margin: 15px 0; padding: 15px; background: rgba(0,0,0,0.02); border-radius: 4px;"><p>{chunk}</p></div>')
    
    # Add images
    images = soup.find_all('img')
    for img in images[:3]:
        if img.get('src'):
            alt_text = img.get('alt', 'Image from original site')
            src = img.get('src')
            content_sections.append(f'<div style="margin: 20px 0; text-align: center; padding: 15px; background: rgba(0,0,0,0.02); border-radius: 4px;"><img src="{src}" alt="{alt_text}" style="max-width: 100%; height: auto; border-radius: 4px;"><p style="margin: 10px 0 0 0; font-style: italic; color: #666;">{alt_text}</p></div>')
    
    # Ensure we have enough content
    while len(content_sections) < 8:
        content_sections.append(f'<div style="margin: 15px 0; padding: 15px; background: rgba(0,0,0,0.02); border-radius: 4px;"><h3 style="color: {primary_color}; margin-top: 0;">Website Section</h3><p>This section represents content from the original website. The AI extracted this information to create a meaningful static representation.</p></div>')
    
    emergency_html = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{
            font-family: {primary_font};
            background-color: {background_color};
            color: {text_color};
            margin: 0;
            padding: 20px;
            line-height: 1.6;
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
            background: {background_color};
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            overflow: hidden;
        }}
        .header {{
            background: {primary_color};
            color: white;
            padding: 30px;
            text-align: center;
        }}
        .content {{
            padding: 30px;
        }}
        h1, h2, h3 {{
            color: {primary_color};
        }}
        .emergency-notice {{
            background: rgba(255, 193, 7, 0.1);
            border: 2px solid #ffc107;
            border-radius: 8px;
            padding: 20px;
            margin-bottom: 30px;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üåü {title}</h1>
            <p>Static Website Clone - Enhanced Content Generation</p>
        </div>
        
        <div class="content">
            <div class="emergency-notice">
                <h3 style="margin-top: 0; color: #856404;">üöÄ Enhanced Content Generation</h3>
                <p style="margin-bottom: 0;">This page was created using advanced content extraction and generation techniques to provide you with a meaningful representation of the original website, complete with substantial content and proper styling.</p>
            </div>
            
            {"".join(content_sections)}
            
            <footer style="margin-top: 40px; padding-top: 20px; border-top: 2px solid {primary_color}; text-align: center; color: #666;">
                <p>Static clone generated with original website styling and content preservation</p>
            </footer>
        </div>
    </div>
</body>
</html>"""
    
    return emergency_html

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
